{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daini10421/Mini-Project-54-Sentiment-Analysis-on-Hospital-Comments/blob/main/Mini_Project_54_Sentiment_Analysis_on_Hospital_Comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "- Private dataset with sensitive hospital comments"
      ],
      "metadata": {
        "id": "NFrtJ38it_67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages"
      ],
      "metadata": {
        "id": "SyNmfMn8t_6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:30:07.992664Z",
          "iopub.execute_input": "2023-06-18T19:30:07.993242Z",
          "iopub.status.idle": "2023-06-18T19:30:24.626287Z",
          "shell.execute_reply.started": "2023-06-18T19:30:07.993198Z",
          "shell.execute_reply": "2023-06-18T19:30:24.62493Z"
        },
        "trusted": true,
        "id": "p4ZZye3xt_6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet2022')\n",
        "\n",
        "! cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet # temp fix for lookup error."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:30:33.037397Z",
          "iopub.execute_input": "2023-06-18T19:30:33.037796Z",
          "iopub.status.idle": "2023-06-18T19:30:35.092891Z",
          "shell.execute_reply.started": "2023-06-18T19:30:33.037767Z",
          "shell.execute_reply": "2023-06-18T19:30:35.091318Z"
        },
        "trusted": true,
        "id": "6vQfAdT5t_6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/private-hospital-comments/comments1.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:30:38.129197Z",
          "iopub.execute_input": "2023-06-18T19:30:38.129659Z",
          "iopub.status.idle": "2023-06-18T19:30:38.214856Z",
          "shell.execute_reply.started": "2023-06-18T19:30:38.129623Z",
          "shell.execute_reply": "2023-06-18T19:30:38.213962Z"
        },
        "trusted": true,
        "id": "rl7TJ3Jit_7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "UwfrAj3jt_7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Main Topic\"] = df[\"Main Topic\"].fillna(\"No Topic Given\")\n",
        "df = df.dropna(subset=[\"Content\"])\n",
        "nan_counts = df.isna().sum()\n",
        "\n",
        "print(nan_counts)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:30:44.465014Z",
          "iopub.execute_input": "2023-06-18T19:30:44.465537Z",
          "iopub.status.idle": "2023-06-18T19:30:44.512748Z",
          "shell.execute_reply.started": "2023-06-18T19:30:44.465499Z",
          "shell.execute_reply": "2023-06-18T19:30:44.51146Z"
        },
        "trusted": true,
        "id": "Xl3NqR6Rt_7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining regex patterns.\n",
        "linebreaks        = \"<br /><br />\"\n",
        "alphaPattern      = \"[^a-z0-9<>]\"\n",
        "sequencePattern   = r\"(.)\\1\\1+\"\n",
        "seqReplacePattern = r\"\\1\\1\"\n",
        "\n",
        "# Defining regex for emojis\n",
        "smileemoji        = r\"[8:=;]['`\\-]?[)d]+\"\n",
        "sademoji          = r\"[8:=;]['`\\-]?\\(+\"\n",
        "neutralemoji      = r\"[8:=;]['`\\-]?[\\/|l*]\"\n",
        "lolemoji          = r\"[8:=;]['`\\-]?p+\"\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "Lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:31:12.707738Z",
          "iopub.execute_input": "2023-06-18T19:31:12.709116Z",
          "iopub.status.idle": "2023-06-18T19:31:12.716709Z",
          "shell.execute_reply.started": "2023-06-18T19:31:12.709074Z",
          "shell.execute_reply": "2023-06-18T19:31:12.715707Z"
        },
        "trusted": true,
        "id": "5ax-t6Tzt_7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_reviews(review):\n",
        "\n",
        "    review = review.lower()\n",
        "\n",
        "    review = re.sub(linebreaks,\" \",review)\n",
        "    # Replace 3 or more consecutive letters by 2 letter.\n",
        "    review = re.sub(sequencePattern, seqReplacePattern, review)\n",
        "\n",
        "    # Replace all emojis.\n",
        "    review = re.sub(r'<3', '<heart>', review)\n",
        "    review = re.sub(smileemoji, '<smile>', review)\n",
        "    review = re.sub(sademoji, '<sadface>', review)\n",
        "    review = re.sub(neutralemoji, '<neutralface>', review)\n",
        "    review = re.sub(lolemoji, '<lolface>', review)\n",
        "\n",
        "    # Remove non-alphanumeric and symbols\n",
        "    review = re.sub(alphaPattern, ' ', review)\n",
        "\n",
        "    # Tokenize the input text\n",
        "    tokens = word_tokenize(review)\n",
        "\n",
        "    # Remove stop words from the token sequence\n",
        "\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Lemmatize the remaining tokens\n",
        "    tokens = [Lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Join the cleaned tokens into a single string\n",
        "    return ' '.join(tokens)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:31:13.088038Z",
          "iopub.execute_input": "2023-06-18T19:31:13.089475Z",
          "iopub.status.idle": "2023-06-18T19:31:13.099343Z",
          "shell.execute_reply.started": "2023-06-18T19:31:13.089427Z",
          "shell.execute_reply": "2023-06-18T19:31:13.09787Z"
        },
        "trusted": true,
        "id": "_OleW3b8t_7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine \"Main Topic\", \"Subtopic\", and \"Content\" columns into a single column called \"Text\"\n",
        "df[\"Text\"] = df[\"Main Topic\"] + \" \" + df[\"Subtopic\"] + \" \" + df[\"Content\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:31:16.400107Z",
          "iopub.execute_input": "2023-06-18T19:31:16.401672Z",
          "iopub.status.idle": "2023-06-18T19:31:16.421833Z",
          "shell.execute_reply.started": "2023-06-18T19:31:16.401605Z",
          "shell.execute_reply": "2023-06-18T19:31:16.420127Z"
        },
        "trusted": true,
        "id": "qO9SRirit_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Text\"] = df[\"Text\"].apply(preprocess_reviews)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:31:18.494098Z",
          "iopub.execute_input": "2023-06-18T19:31:18.494588Z",
          "iopub.status.idle": "2023-06-18T19:31:26.295927Z",
          "shell.execute_reply.started": "2023-06-18T19:31:18.494553Z",
          "shell.execute_reply": "2023-06-18T19:31:26.294695Z"
        },
        "trusted": true,
        "id": "84aHaSset_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyword and Sentiment Analysis using Word2Vec\n",
        "- Reference Article: https://towardsdatascience.com/unsupervised-semantic-sentiment-analysis-of-imdb-reviews-2c5f520fbf81"
      ],
      "metadata": {
        "id": "YUs3aI02t_7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/towardsNLP/IMDB-Semantic-Sentiment-Analysis/main/Word2Vec/src/w2v_utils.py -o w2v_utils.py"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:23.425327Z",
          "iopub.execute_input": "2023-06-18T19:34:23.425827Z",
          "iopub.status.idle": "2023-06-18T19:34:25.869583Z",
          "shell.execute_reply.started": "2023-06-18T19:34:23.425791Z",
          "shell.execute_reply": "2023-06-18T19:34:25.868452Z"
        },
        "trusted": true,
        "id": "XgWNPM4ht_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from w2v_utils import (Tokenizer,\n",
        "                       evaluate_model,\n",
        "                       bow_vectorizer,\n",
        "                       train_logistic_regressor,\n",
        "                       w2v_trainer,\n",
        "                       calculate_overall_similarity_score,\n",
        "                       overall_semantic_sentiment_analysis,\n",
        "                       list_similarity,\n",
        "                       calculate_topn_similarity_score,\n",
        "                       topn_semantic_sentiment_analysis,\n",
        "                       define_complexity_subjectivity_reviews,\n",
        "                       explore_high_complexity_reviews,\n",
        "                       explore_low_subjectivity_reviews,\n",
        "                       text_SSA)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:25.87231Z",
          "iopub.execute_input": "2023-06-18T19:34:25.872693Z",
          "iopub.status.idle": "2023-06-18T19:34:27.331902Z",
          "shell.execute_reply.started": "2023-06-18T19:34:25.872661Z",
          "shell.execute_reply": "2023-06-18T19:34:27.330557Z"
        },
        "trusted": true,
        "id": "8qujLJBFt_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instancing the Tokenizer class\n",
        "tokenizer = Tokenizer(clean= True,\n",
        "                      lower= True,\n",
        "                      de_noise= True,\n",
        "                      remove_stop_words= True,\n",
        "                      keep_negation=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:30.746511Z",
          "iopub.execute_input": "2023-06-18T19:34:30.746968Z",
          "iopub.status.idle": "2023-06-18T19:34:30.754911Z",
          "shell.execute_reply.started": "2023-06-18T19:34:30.746937Z",
          "shell.execute_reply": "2023-06-18T19:34:30.753301Z"
        },
        "trusted": true,
        "id": "rUad20dqt_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized_text'] = df['Text'].apply(tokenizer.tokenize)\n",
        "\n",
        "df['tokenized_text_len'] = df['tokenized_text'].apply(len)\n",
        "df['tokenized_text_len'].apply(np.log).describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:32.828657Z",
          "iopub.execute_input": "2023-06-18T19:34:32.829108Z",
          "iopub.status.idle": "2023-06-18T19:34:33.742275Z",
          "shell.execute_reply.started": "2023-06-18T19:34:32.829078Z",
          "shell.execute_reply": "2023-06-18T19:34:33.741097Z"
        },
        "trusted": true,
        "id": "mdX9rY6tt_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors , keyed_vocab = w2v_trainer(df[\"tokenized_text\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:38.983321Z",
          "iopub.execute_input": "2023-06-18T19:34:38.983854Z",
          "iopub.status.idle": "2023-06-18T19:34:41.645314Z",
          "shell.execute_reply.started": "2023-06-18T19:34:38.983796Z",
          "shell.execute_reply": "2023-06-18T19:34:41.644004Z"
        },
        "trusted": true,
        "id": "3w7uThaut_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(keyed_vectors))\n",
        "print(type(keyed_vocab))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:42.723907Z",
          "iopub.execute_input": "2023-06-18T19:34:42.725406Z",
          "iopub.status.idle": "2023-06-18T19:34:42.730921Z",
          "shell.execute_reply.started": "2023-06-18T19:34:42.725357Z",
          "shell.execute_reply": "2023-06-18T19:34:42.729701Z"
        },
        "trusted": true,
        "id": "CM6aOxGWt_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors.most_similar(\"research\",topn=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:44.848228Z",
          "iopub.execute_input": "2023-06-18T19:34:44.848652Z",
          "iopub.status.idle": "2023-06-18T19:34:44.880546Z",
          "shell.execute_reply.started": "2023-06-18T19:34:44.848624Z",
          "shell.execute_reply": "2023-06-18T19:34:44.878682Z"
        },
        "trusted": true,
        "id": "_9jRFx0ut_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors.most_similar(\"hospital\",topn=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:49.254794Z",
          "iopub.execute_input": "2023-06-18T19:34:49.255279Z",
          "iopub.status.idle": "2023-06-18T19:34:49.275791Z",
          "shell.execute_reply.started": "2023-06-18T19:34:49.255244Z",
          "shell.execute_reply": "2023-06-18T19:34:49.273886Z"
        },
        "trusted": true,
        "id": "i_FwmdyWt_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyed_vectors.most_similar(\"funded\",topn=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:49.572073Z",
          "iopub.execute_input": "2023-06-18T19:34:49.572496Z",
          "iopub.status.idle": "2023-06-18T19:34:49.589402Z",
          "shell.execute_reply.started": "2023-06-18T19:34:49.572459Z",
          "shell.execute_reply": "2023-06-18T19:34:49.587596Z"
        },
        "trusted": true,
        "id": "0nX64KaLt_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering Approach to Sentiment Analysis"
      ],
      "metadata": {
        "id": "2iozlBPFt_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To make sure that all `positive_concepts` are in the keyed word2vec vocabulary\n",
        "positive_concepts = ['excellent', 'awesome', 'cool','decent','amazing', 'strong', 'good', 'great', 'funny', 'entertaining']\n",
        "pos_concepts = [concept for concept in positive_concepts if concept in keyed_vocab]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:54.508288Z",
          "iopub.execute_input": "2023-06-18T19:34:54.508781Z",
          "iopub.status.idle": "2023-06-18T19:34:54.514775Z",
          "shell.execute_reply.started": "2023-06-18T19:34:54.508743Z",
          "shell.execute_reply": "2023-06-18T19:34:54.513872Z"
        },
        "trusted": true,
        "id": "YK9rjrJit_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To make sure that all `negative_concepts` are in the keyed word2vec vocabulary\n",
        "negative_concepts = ['terrible','awful','horrible','boring','bad', 'disappointing', 'weak', 'poor',  'senseless','confusing']\n",
        "neg_concepts = [concept for concept in negative_concepts if concept in keyed_vocab]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:54.869381Z",
          "iopub.execute_input": "2023-06-18T19:34:54.870087Z",
          "iopub.status.idle": "2023-06-18T19:34:54.875218Z",
          "shell.execute_reply.started": "2023-06-18T19:34:54.870053Z",
          "shell.execute_reply": "2023-06-18T19:34:54.874019Z"
        },
        "trusted": true,
        "id": "IBAoISpzt_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Semantic Sentiment Scores by OSSA model\n",
        "overall_df_scores = overall_semantic_sentiment_analysis (keyed_vectors = keyed_vectors,\n",
        "                                                   positive_target_tokens = pos_concepts,\n",
        "                                                   negative_target_tokens = neg_concepts,\n",
        "                                                   doc_tokens = df['tokenized_text'])\n",
        "\n",
        "# Calculating Semantic Sentiment Scores by TopSSA model\n",
        "topn_df_scores = topn_semantic_sentiment_analysis (keyed_vectors = keyed_vectors,\n",
        "                                                   positive_target_tokens = pos_concepts,\n",
        "                                                   negative_target_tokens = neg_concepts,\n",
        "                                                   doc_tokens = df['tokenized_text'],\n",
        "                                                     topn=30)\n",
        "\n",
        "\n",
        "# To store semantic sentiment store computed by OSSA model in df\n",
        "df['overall_PSS'] = overall_df_scores[0]\n",
        "df['overall_NSS'] = overall_df_scores[1]\n",
        "df['overall_semantic_sentiment_score'] = overall_df_scores[2]\n",
        "df['overall_semantic_sentiment_polarity'] = overall_df_scores[3]\n",
        "\n",
        "\n",
        "\n",
        "# To store semantic sentiment store computed by TopSSA model in df\n",
        "df['topn_PSS'] = topn_df_scores[0]\n",
        "df['topn_NSS'] = topn_df_scores[1]\n",
        "df['topn_semantic_sentiment_score'] = topn_df_scores[2]\n",
        "df['topn_semantic_sentiment_polarity'] = topn_df_scores[3]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:34:55.957204Z",
          "iopub.execute_input": "2023-06-18T19:34:55.958469Z",
          "iopub.status.idle": "2023-06-18T19:35:04.205327Z",
          "shell.execute_reply.started": "2023-06-18T19:34:55.958419Z",
          "shell.execute_reply": "2023-06-18T19:35:04.204181Z"
        },
        "trusted": true,
        "id": "IAKSKvZ-t_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = keyed_vectors.index_to_key\n",
        "vectors = [keyed_vectors[word] for word in words]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:35:04.207369Z",
          "iopub.execute_input": "2023-06-18T19:35:04.207689Z",
          "iopub.status.idle": "2023-06-18T19:35:04.223254Z",
          "shell.execute_reply.started": "2023-06-18T19:35:04.207663Z",
          "shell.execute_reply": "2023-06-18T19:35:04.222263Z"
        },
        "trusted": true,
        "id": "_69h95uvt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(vectors)\n",
        "\n",
        "# Create a DataFrame with PCA results and words\n",
        "pca_df = pd.DataFrame(result, columns=['x', 'y'])\n",
        "pca_df['word'] = words\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:35:06.272749Z",
          "iopub.execute_input": "2023-06-18T19:35:06.273568Z",
          "iopub.status.idle": "2023-06-18T19:35:06.537157Z",
          "shell.execute_reply.started": "2023-06-18T19:35:06.273517Z",
          "shell.execute_reply": "2023-06-18T19:35:06.535419Z"
        },
        "trusted": true,
        "id": "ndPckSgHt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "fig = go.Figure(data=go.Scattergl(\n",
        "    x=pca_df['x'],\n",
        "    y=pca_df['y'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        colorscale='Viridis',\n",
        "        line_width=1\n",
        "    ),\n",
        "    text=pca_df['word'],\n",
        "    textposition=\"bottom center\"\n",
        "))\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:35:12.359696Z",
          "iopub.execute_input": "2023-06-18T19:35:12.360207Z",
          "iopub.status.idle": "2023-06-18T19:35:12.578223Z",
          "shell.execute_reply.started": "2023-06-18T19:35:12.360156Z",
          "shell.execute_reply": "2023-06-18T19:35:12.576069Z"
        },
        "trusted": true,
        "id": "JRWOfXuat_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_pos_filt = df['topn_semantic_sentiment_polarity'] == 1\n",
        "actual_neg_filt =  df['topn_semantic_sentiment_polarity'] == 0\n",
        "\n",
        "# filter positive and negative review based on Most Probable predicted 'y' or 'topn_semantic_sentiment_score' column\n",
        "predicted_pos_filt = df['topn_semantic_sentiment_polarity'] == 1\n",
        "predicted_neg_filt = df['topn_semantic_sentiment_polarity'] == 0\n",
        "\n",
        "\n",
        "\n",
        "# plotting Semantic Sentiment Score Position of Actual Negative Reviews\n",
        "plt.scatter(df['topn_NSS'][actual_neg_filt],\n",
        "         df['topn_PSS'][actual_neg_filt],\n",
        "         label='Actual Negetive Reviews',\n",
        "           color='DarkRed',\n",
        "            alpha=0.4 , # set transparency of color\n",
        "            s=20 # set size of dots\n",
        "           )\n",
        "\n",
        "# plotting Semantic Sentiment Score Position of Actual Positive Reviews\n",
        "plt.scatter(df['topn_NSS'][actual_pos_filt],\n",
        "         df['topn_PSS'][actual_pos_filt],\n",
        "         label='Actual Positive Reviews',\n",
        "       color='DarkGreen',\n",
        "            alpha=0.1, # set transparency of color\n",
        "            s=30 # set size of dots\n",
        "           )\n",
        "# naming the x & y axis\n",
        "plt.xlabel('Predicted Negative Labels')\n",
        "plt.ylabel('Predicted Positive Labels')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:35:27.012902Z",
          "iopub.execute_input": "2023-06-18T19:35:27.01338Z",
          "iopub.status.idle": "2023-06-18T19:35:27.383845Z",
          "shell.execute_reply.started": "2023-06-18T19:35:27.013345Z",
          "shell.execute_reply": "2023-06-18T19:35:27.382247Z"
        },
        "trusted": true,
        "id": "uptrhOnAt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis Using BERT"
      ],
      "metadata": {
        "id": "IWT34LLet_7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:35:35.314457Z",
          "iopub.execute_input": "2023-06-18T19:35:35.314915Z",
          "iopub.status.idle": "2023-06-18T19:35:50.497772Z",
          "shell.execute_reply.started": "2023-06-18T19:35:35.314882Z",
          "shell.execute_reply": "2023-06-18T19:35:50.496282Z"
        },
        "trusted": true,
        "id": "jupyaHuCt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing the pipeline module\n",
        "from transformers import pipeline\n",
        "\n",
        "# Downloading the sentiment analysis model\n",
        "SentimentClassifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Downloading the sentiment analysis model\n",
        "# SentimentClassifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:36:11.542487Z",
          "iopub.execute_input": "2023-06-18T19:36:11.542899Z",
          "iopub.status.idle": "2023-06-18T19:36:16.356202Z",
          "shell.execute_reply.started": "2023-06-18T19:36:11.542868Z",
          "shell.execute_reply": "2023-06-18T19:36:16.355142Z"
        },
        "trusted": true,
        "id": "_uYFL-v7t_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to call for the whole dataframe\n",
        "def FunctionBERTSentiment(inpText):\n",
        "  return(SentimentClassifier(inpText)[0]['label'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:36:16.358795Z",
          "iopub.execute_input": "2023-06-18T19:36:16.360277Z",
          "iopub.status.idle": "2023-06-18T19:36:16.366894Z",
          "shell.execute_reply.started": "2023-06-18T19:36:16.360225Z",
          "shell.execute_reply": "2023-06-18T19:36:16.365623Z"
        },
        "trusted": true,
        "id": "lleViIhXt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['BERT_Sentiment']=df['Text'].apply(FunctionBERTSentiment)\n",
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:36:16.368978Z",
          "iopub.execute_input": "2023-06-18T19:36:16.370216Z",
          "iopub.status.idle": "2023-06-18T19:41:19.091565Z",
          "shell.execute_reply.started": "2023-06-18T19:36:16.370142Z",
          "shell.execute_reply": "2023-06-18T19:41:19.090276Z"
        },
        "trusted": true,
        "id": "IQmbuccdt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to call for the whole dataframe\n",
        "def FunctionBERTScore(inpText):\n",
        "  return(SentimentClassifier(inpText)[0]['score'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:46:12.227331Z",
          "iopub.execute_input": "2023-06-18T19:46:12.227813Z",
          "iopub.status.idle": "2023-06-18T19:46:12.234674Z",
          "shell.execute_reply.started": "2023-06-18T19:46:12.22777Z",
          "shell.execute_reply": "2023-06-18T19:46:12.233506Z"
        },
        "trusted": true,
        "id": "KugyYC_bt_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Score']=df['Text'].apply(FunctionBERTScore)\n",
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:46:12.236459Z",
          "iopub.execute_input": "2023-06-18T19:46:12.236875Z",
          "iopub.status.idle": "2023-06-18T19:51:01.698258Z",
          "shell.execute_reply.started": "2023-06-18T19:46:12.23684Z",
          "shell.execute_reply": "2023-06-18T19:51:01.69696Z"
        },
        "trusted": true,
        "id": "BTdXKt65t_7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Content_BERT_Sentiment']=df['Content'].apply(FunctionBERTSentiment)\n",
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:51:01.700267Z",
          "iopub.execute_input": "2023-06-18T19:51:01.701044Z",
          "iopub.status.idle": "2023-06-18T19:56:17.459349Z",
          "shell.execute_reply.started": "2023-06-18T19:51:01.701Z",
          "shell.execute_reply": "2023-06-18T19:56:17.457931Z"
        },
        "trusted": true,
        "id": "LaXrsW1Gt_7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('bert_sentiment.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:56:17.461213Z",
          "iopub.execute_input": "2023-06-18T19:56:17.46168Z",
          "iopub.status.idle": "2023-06-18T19:56:17.46782Z",
          "shell.execute_reply.started": "2023-06-18T19:56:17.461638Z",
          "shell.execute_reply": "2023-06-18T19:56:17.466633Z"
        },
        "trusted": true,
        "id": "u3FJTJiLt_7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, subPlot =plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "fig.suptitle(\"Sentiment analysis of Content + Topic Text\")\n",
        "\n",
        "# Grouping the data\n",
        "GroupedData=df.groupby('BERT_Sentiment').size()\n",
        "\n",
        "# Creating the charts\n",
        "GroupedData.plot(kind='bar', ax=subPlot[0], color=['crimson', 'lightblue'])\n",
        "GroupedData.plot(kind='pie', ax=subPlot[1], colors=['crimson', 'lightblue'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:56:17.469518Z",
          "iopub.execute_input": "2023-06-18T19:56:17.469965Z",
          "iopub.status.idle": "2023-06-18T19:56:17.881077Z",
          "shell.execute_reply.started": "2023-06-18T19:56:17.469927Z",
          "shell.execute_reply": "2023-06-18T19:56:17.879872Z"
        },
        "trusted": true,
        "id": "w0mRw2Fit_7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, subPlot =plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "fig.suptitle(\"Sentiment analysis of Content Only\")\n",
        "\n",
        "# Grouping the data\n",
        "GroupedData=df.groupby('Content_BERT_Sentiment').size()\n",
        "\n",
        "# Creating the charts\n",
        "GroupedData.plot(kind='bar', ax=subPlot[0], color=['crimson', 'lightblue'])\n",
        "GroupedData.plot(kind='pie', ax=subPlot[1], colors=['crimson', 'lightblue'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-18T19:56:17.882669Z",
          "iopub.execute_input": "2023-06-18T19:56:17.883593Z",
          "iopub.status.idle": "2023-06-18T19:56:18.23276Z",
          "shell.execute_reply.started": "2023-06-18T19:56:17.883557Z",
          "shell.execute_reply": "2023-06-18T19:56:18.231502Z"
        },
        "trusted": true,
        "id": "R0Mq9tBWt_7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}